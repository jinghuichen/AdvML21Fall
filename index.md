# IST 597: Adversarial Machine Learning 

## Overview

Machine learning techniques are prevalent in solving real-world problems, however, they are also found to be vulnerable to malicious adversaries. This has raised serious security concerns and trustworthy issues in the current machine learning systems. In this course, students will learn about understanding the risks posed by adversaries to the current machine learning systems, as well as designing more advanced defense techniques to mitigate those risks. 

This course is focused on helping students explore new research directions and applications in Adversarial Machine Learning. As part of this focus, students will understand the vulnerabilities of different machine learning algorithms or improve the current machine learning model robustness through a series of readings and projects.
 

## Prerequisites
This course requires knowledge of machine learning (DS 310 or equivalent), basic linear algebra and programming principles.

## Logistics

- Time: **Thursday 2:30PM - 5:30PM**
- Location: **Westgate Bldg E210**  
- Instructor: [Jinghui Chen](https://www.personal.psu.edu/jzc5917/) (Email: jzc5917 at psu dot edu)   
     
- Office hours: 
    - The instructor's office hour is Thursday after class. 
     
- Course Website: [https://jinghuichen.github.io/AdvML21Fall/](https://jinghuichen.github.io/AdvML21Fall/)
- Canvas: [https://psu.instructure.com/courses/2150316](https://psu.instructure.com/courses/2150316)

## Grading Policy
 
Grades will be computed based on the following factors:

- Final Project  50%
- Paper Presentation   30%
- Paper Reviews  15%
- Class Participation  5% 

Final grade cutoff:
- A [93%, 100%]
- A- [90%, 93%)
- B+ [87%, 90%)
- B [83%, 87%)
- B- [80%, 83%)
- C+ [77%, 80%)
- C [70%, 77%)
- D [60%, 70%)
- F [0%, 60%)


## Schedule


| # | Date | Topics | Reading | Homework |
| - | ---- | ------ | ------- | -------- |
| 1 | 08/26 | Course Introduction (Adversarial ML) | | |
| 2 | 09/02 | Adversarial Attacks Against Machine Learning Models | | Reading Signup |
| 3 | 09/09 | Defenses against Adversarial Attacks | |   |
| 4 | 09/16 | Proposal Presentation | | Final Proj Proposal Due  |
| 5 | 09/23 | Poisoning Attacks and Defenses & Paper Presentation | |   |
| 6 | 09/30 | Backdoor Attacks and Defenses & Paper Presentation | |   |
| 7 | 10/07 | Privacy Attacks for Machine Learning Models & Paper Presentation | |   |
| 8 | 10/14 | Privacy Defenses for Machine Learning Models & Paper Presentation | |   |
| 9 | 10/21 | Confidentiality of Machine Learning Models & Paper Presentation | |   |
| 10 | 10/28 | Project Midterm Presenetation | | Proj Midterm Report Due  |
| 11 | 11/04 | Graph Adversarial Attacks and Defenses & Paper Presentation | |   |
| 12 | 11/11 | Physical World Adversarial Machine Learning & Paper Presentation | |   |
| 13 | 11/18 | Robustness In Distributed Learning/Self-Supervised Learning/Reinforcement Learning & Paper Presentation | |   |
| 14 | 11/25 | No Class (Thanksgiving Holiday) | |   |
| 15 | 12/02 | Final Project Presentation | | Paper Review Report Due  |
| 16 | 12/09 | Final Project Presentation | | Final Project Report Due  |


 
 
 


## Paper Presentation 
- Each student will present 2-3 papers (based on the hardness of the paper) for a specific topic. Students need to sign up for the presentation before Week 2. 
- Students are expected to prepare the slides by themselves, but the original authors’ slides are allowed to be used with proper citation.
- The presentation quality will take 30% of your grade.

## Paper Reviews 
- Each student will review 3 papers from the piles that other students presented (different from the papers you presented).  
- Each review should contain a basic introduction to the background, drawbacks of prior solutions (if any), proposed problem formulations/analysis and your understanding towards the advantages and disadvantages of the proposed method/analysis as well as the possible future directions.
- The review quality will take 15% of your grade.

## Final Project 
- Group is allowed for the final project (with a maximum of 2 people per group). The expectation for a 2-people group will be relatively higher.
- The goal of the course project is to provide the students an opportunity to explore research directions in adversarial machine learning. Therefore, the project should be related to the course content. An expected project include but not limited to
    - A novel and sound solution to an interesting problem
    - Solving an interesting new real-world problem with adversarial machine learning 
    - Thorough theoretical analysis of existing approaches
- The best outcome of the project is a manuscript that is publishable in major machine learning/AI/Security conferences (ICML, NeurIPS, ICLR, CVPR, KDD, ACL, CCS, etc.).
- The final project quality will take 50% of your grade.
- **Students cannot use their own published work as the course project.**


## Late Submission Policy
- All reports are due on Thursday at 11:59 pm (EST).
- Students can submit late with the penalty of 25% deduction for every 12 hours late (up to 2 days).
- After 2 days, no more late submission is allowed.
- Extensions can be granted for special cases (email the instructor)




## Academic Integrity Policy
According to the Penn State Principles and University Code of Conduct: Academic integrity is a basic guiding principle for all academic activity at Penn State University, allowing the pursuit of scholarly activity in an open, honest, and responsible manner. In accordance with the University’s Code of Conduct, you must not engage in or tolerate academic dishonesty. This includes, but is not limited to cheating, plagiarism, fabrication of information or citations, facilitating acts of academic dishonesty by others, unauthorized possession of examinations, submitting work of another person, or work previously used without informing the instructor, or tampering with the academic work of other students. Any violation of academic integrity will be investigated, and where warranted, punitive action will be taken. For every incident when a penalty of any kind is assessed, a report must be filed.

Plagiarism (Cheating): Talking over your ideas and getting comments on your writing from friends are NOT examples of plagiarism. Taking someone else’s words (published or not) and calling them your own IS plagiarism. Plagiarism has dire consequences, including flunking the paper in question, flunking the course, and university disciplinary action, depending on the circumstances of the office. The simplest way to avoid plagiarism is to document the sources of your information carefully.
 
## Disability Access Statement
Americans with Disabilities Act: The School of Information Sciences and Technology welcomes persons with disabilities to all of its classes, programs, and events. If you need accommodations or have questions about access to buildings where IST activities are held, please contact us in advance of your participation or visit. If you need assistance during a class, program, or event, please contact the member of our staff or faculty in charge. Access to IST courses should be arranged by contacting the Office of Human Resources, 332 IST Building: (814) 865-8949.

Students with Disabilities: It is Penn State’s policy to not discriminate against qualified students with documented disabilities in its educational programs. (You may refer to the Nondiscrimination Policy in the Student Guide to University Policies and Rules.) If you have a disability-related need for reasonable academic adjustments in this course, contact the Office for Disability Services (ODS) at 814-863-1807 (V/TTY). For further information regarding ODS, please visit the Office for Disability Services Web site at http://equity.psu.edu/ods/.

In order to receive consideration for course accommodations, you must contact ODS and provide documentation (see documentation guidelines at http://equity.psu.edu/ods/guidelines/documentation-guidelines). If the documentation supports the need for academic adjustments, ODS will provide a letter identifying appropriate academic adjustments. Please share this letter and discuss the adjustments with your instructor as early in the course as possible. You must contact ODS and request academic adjustment letters at the beginning of each semester.

## Statement on Nondiscrimination & Harassment (Policy AD42)
The Pennsylvania State University is committed to the policy that all persons shall have equal access to programs, facilities, admission and employment without regard to personal characteristics not related to ability, performance, or qualifications as determined by University policy or by state or federal authorities. It is the policy of the University to maintain an academic and work environment free of discrimination, including harassment. The Pennsylvania State University prohibits discrimination and harassment against any person because of age, ancestry, color, disability or handicap, national origin, race, religious creed, sex, sexual orientation, gender identity or veteran status. Discrimination or harassment against faculty, staff or students will not be tolerated at The Pennsylvania State University. You may direct inquiries to the Office of Multicultural Affairs, 332 Information Sciences and Technology Building, University Park, PA 16802; Tel 814-865-0077 or to the Office of Affirmative Action, 328 Boucke Building, University Park, PA 16802-5901; Tel 814-865-4700/V, 814-863-1150/TTY.

For reference to the full policy (Policy AD42: Statement on Nondiscrimination and Harassment): http://guru.psu.edu/policies/AD42.html

